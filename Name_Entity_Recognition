import nltk
from nltk.corpus import state_union
from nltk.tokenize import PunktSentenceTokenizer
# unsupervised learning

train_text = state_union.raw("2005-GWBush.txt")
sample_text = state_union.raw("2006-GWBush.txt")

#customer_sent_tokenizer = PunktSentenceTokenizer(sample_text)
customer_sent_tokenizer = PunktSentenceTokenizer(train_text)

tokenized = customer_sent_tokenizer.tokenize(sample_text)

for w in tokenized:
     words = nltk.word_tokenize(w)
     tagged = nltk.pos_tag(words)
     namedEnt = nltk.ne_chunk(tagged)
     namedEnt = nltk.ne_chunk(tagged, binary = true)
     namedEnt.draw()
